{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import mat73\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils import data\n",
    "from torch import nn\n",
    "from scipy.io import loadmat\n",
    "from scipy.io import savemat\n",
    "from torchvision import transforms\n",
    "\n",
    "import torch.utils.model_zoo as model_zoo\n",
    "import torch.onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "#verify cuda is accesible - if not, check drivers\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('Using {} device'.format(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hyperparameters\n",
    "\n",
    "HOLD_OUT_VAL = 0.01\n",
    "HOLD_OUT_TEST = 0.02\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "HIDDEN_NODES = 512\n",
    "LEARNING_RATE = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_data (1000, 9)\n",
      "Shape of Y_data (1000, 976)\n"
     ]
    }
   ],
   "source": [
    "#load the matlab dataset(s)\n",
    "\n",
    "raw_data = mat73.loadmat('training_data_landing_normalized.mat')\n",
    "\n",
    "#print(raw_data.keys())\n",
    "\n",
    "X_data = np.swapaxes(raw_data['training_data_normalized']['input'],0,1)\n",
    "Y_data = np.swapaxes(raw_data['training_data_normalized']['output'],0,1)\n",
    "\n",
    "print('Shape of X_data ' + str(X_data.shape))\n",
    "print('Shape of Y_data ' + str(Y_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 976])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert numpy array to pytorch tensor for data\n",
    "\n",
    "input_data = torch.from_numpy(X_data).float()\n",
    "output_data = torch.from_numpy(Y_data).float()\n",
    "\n",
    "#   0 - 251 : X_star\n",
    "# 252 - 731: U_star\n",
    "# 731 - 972: jpos_star\n",
    "output_data.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the datasets\n",
    "\n",
    "export_normalization_parameters = True;\n",
    "normalization_method = \"Min-max\"\n",
    "\n",
    "if (normalization_method == \"Gaussian\"): # Gaussian normalization\n",
    "    input_mean = torch.mean(input_data,0)\n",
    "    input_std = torch.std(input_data,0)\n",
    "    input_std[input_std==0]=1\n",
    "    normalized_input = (input_data - input_mean[None,:])/input_std[None,:]\n",
    "\n",
    "    output_mean = torch.mean(output_data,0)\n",
    "    output_std = torch.std(output_data,0)\n",
    "    output_std[output_std==0]=1\n",
    "    normalized_output = (output_data - output_mean[None,:])/output_std[None,:]\n",
    "    if export_normalization_parameters:    \n",
    "        input_mu_export = input_mean.detach().cpu().numpy()   # Gaussian normalization\n",
    "        input_std_export = input_std.detach().cpu().numpy()\n",
    "        output_mu_export = output_mean.detach().cpu().numpy()\n",
    "        output_std_export = output_std.detach().cpu().numpy()\n",
    "        data_params = {\"input_mean\": input_mu_export, \"input_std\": input_std_export, \n",
    "                  \"output_mean\": output_mu_export, \"output_std\": output_std_export}\n",
    "        savemat(\"data_params.mat\", data_params)\n",
    "\n",
    "elif (normalization_method == \"Min-max\"): # Min-max scale normalization\n",
    "    [input_min, input_min_index] = torch.min(input_data, 0); \n",
    "    [input_max, input_max_index] = torch.max(input_data, 0); \n",
    "    input_range = input_max - input_min; \n",
    "    input_range[input_range == 0] = 1;\n",
    "    normalized_input = (input_data - input_min[None, :])/input_range[None, :]; \n",
    "\n",
    "    [output_min, output_min_index] = torch.min(output_data, 0);\n",
    "    [output_max, output_max_index] = torch.max(output_data, 0);\n",
    "    output_range = output_max - output_min;\n",
    "    output_range[output_range == 0] = 1;\n",
    "    normalized_output = (output_data - output_min[None, :])/output_range[None, :];\n",
    "    \n",
    "    if export_normalization_parameters:\n",
    "        input_min_export = input_min.detach().cpu().numpy();\n",
    "        input_range_export = input_range.detach().cpu().numpy();\n",
    "        output_min_export = output_min.detach().cpu().numpy();\n",
    "        output_range_export = output_range.detach().cpu().numpy();\n",
    "        data_params = {\"input_min\": input_min_export, \"input_range\": input_range_export, \n",
    "                   \"output_min\": output_min_export, \"output_range\": output_range_export}\n",
    "        savemat(\"data_params.mat\", data_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set size: 10, Test set size: 20, Training set size: 970\n",
      "torch.Size([64, 9]) torch.Size([64, 976])\n"
     ]
    }
   ],
   "source": [
    "#create the dataset from the input and output data\n",
    "# samples = data.TensorDataset(normalized_input, normalized_output)\n",
    "samples = data.TensorDataset(input_data, output_data)\n",
    "\n",
    "#define dataset sizes by hyperparameters\n",
    "val_size = int(len(samples) * HOLD_OUT_VAL)\n",
    "test_size = int(len(samples) * HOLD_OUT_TEST)\n",
    "train_size = len(samples) - val_size - test_size\n",
    "print('Validation set size: ' + str(val_size) + \n",
    "      ', Test set size: ' + str(test_size) + \n",
    "      ', Training set size: ' + str(train_size))\n",
    "\n",
    "#randomly split the dataset into training, validation, and test sets\n",
    "train, val, test = data.random_split(samples, (train_size, val_size, test_size))\n",
    "\n",
    "#create loaders for each dataset\n",
    "train_loader = data.DataLoader(train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = data.DataLoader(val, batch_size=BATCH_SIZE)\n",
    "test_loader = data.DataLoader(test, batch_size=BATCH_SIZE)\n",
    "\n",
    "#sanity check batching and sizes are correct\n",
    "for batch_idx, (x, y) in enumerate(train_loader):\n",
    "    print(x.shape, y.shape)\n",
    "    break;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=9, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=512, out_features=976, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(9, HIDDEN_NODES),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(HIDDEN_NODES, HIDDEN_NODES),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(HIDDEN_NODES, HIDDEN_NODES),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(HIDDEN_NODES, 976),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "print(model)\n",
    "\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_network(dataloader, model, loss_fn, optimizer, t, p):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #TODO: fix this code\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            if t%p==(p-1): print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_network(dataloader, model, loss_fn, t, p):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "    test_loss /= num_batches\n",
    "    if t%p==(p-1):print(f\"Test Error: Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#traing control variables\n",
    "EPOCHS = 5000\n",
    "PRINT_EVERY = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500\n",
      "-------------------------------\n",
      "loss: 0.005737  [    0/  970]\n",
      "Test Error: Avg loss: 0.377994 \n",
      "\n",
      "Epoch 1000\n",
      "-------------------------------\n",
      "loss: 0.001892  [    0/  970]\n",
      "Test Error: Avg loss: 0.376255 \n",
      "\n",
      "Epoch 1500\n",
      "-------------------------------\n",
      "loss: 0.001462  [    0/  970]\n",
      "Test Error: Avg loss: 0.370700 \n",
      "\n",
      "Epoch 2000\n",
      "-------------------------------\n",
      "loss: 0.012217  [    0/  970]\n",
      "Test Error: Avg loss: 0.374415 \n",
      "\n",
      "Epoch 2500\n",
      "-------------------------------\n",
      "loss: 0.002004  [    0/  970]\n",
      "Test Error: Avg loss: 0.373771 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#run training\n",
    "start = time.process_time()\n",
    "for t in range(EPOCHS):\n",
    "    if t%PRINT_EVERY==(PRINT_EVERY-1): print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_network(train_loader, model, loss_fn, optimizer, t, PRINT_EVERY)\n",
    "    test_network(test_loader, model, loss_fn, t, PRINT_EVERY)\n",
    "end = time.process_time()\n",
    "print('Done! in ' + str((end-start)*1000) + 'ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#validation and csv printing variables\n",
    "VALIDATION_ENTRY = 3\n",
    "FILE_NUMBER = 0\n",
    "CSV = True\n",
    "SAVE = True\n",
    "EXPORT = True\n",
    "EXPORT_CPP=True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#used to test cpu evaluation time - comment out normally\n",
    "#model.to('cpu')\n",
    "#model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to compute: 0.29634699995995106ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Min-max'"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#compute a validation sample with the trained model\n",
    "\n",
    "for x, y in val_loader:\n",
    "    x_sample = x[VALIDATION_ENTRY].to(device)\n",
    "    y_sample = y[VALIDATION_ENTRY].to(device)\n",
    "\n",
    "start = time.process_time()\n",
    "pred = model(x_sample[None])\n",
    "end = time.process_time()\n",
    "\n",
    "print('Time to compute: ' + str((end-start)*1000) + 'ms')\n",
    "\n",
    "normalization_method == \"Normalized\"\n",
    "\n",
    "if (normalization_method == \"Gaussian\"):\n",
    "    x = (x_sample.squeeze().cpu()*input_std + input_mean)\n",
    "    pred = (pred.squeeze().cpu()*output_std + output_mean)\n",
    "    y = (y_sample.squeeze().cpu()*output_std + output_mean)\n",
    "    \n",
    "elif (normalization_method == \"Min-max\"):\n",
    "    x = (x_sample.squeeze().cpu()*input_range + input_min)\n",
    "    pred = (pred.squeeze().cpu()*output_range + output_min)\n",
    "    y = (y_sample.squeeze().cpu()*output_range + output_min)\n",
    "elif (normalization_method == \"Normalized\"):\n",
    "    x = (x_sample.squeeze().cpu())\n",
    "    pred = (pred.squeeze().cpu())\n",
    "    y = (y_sample.squeeze().cpu())   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the solution y from validation to a csv\n",
    "if CSV:\n",
    "    y_np = y.numpy()\n",
    "    y_df = pd.DataFrame(y_np)\n",
    "    y_df.to_csv('sehwan_csv/output_' + str(FILE_NUMBER) + '.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the model prediction pred from validation to a csv\n",
    "if CSV:\n",
    "    pred_np = pred.detach().numpy()\n",
    "    pred_df = pd.DataFrame(pred_np)\n",
    "    pred_df.to_csv('sehwan_csv/nnpred_' + str(FILE_NUMBER) + '.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print the model prediction pred from validation to a csv\n",
    "if CSV:\n",
    "    x_np = x.detach().numpy()\n",
    "    x_df = pd.DataFrame(x_np)\n",
    "    x_df.to_csv('sehwan_csv/input_' + str(FILE_NUMBER) + '.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the trained model\n",
    "if SAVE: torch.save(model.state_dict(), 'sehwan_landing_2x512')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph(%0 : Float(1, 9, strides=[9, 1], requires_grad=0, device=cpu),\n",
      "      %linear_relu_stack.0.weight : Float(512, 9, strides=[9, 1], requires_grad=1, device=cpu),\n",
      "      %linear_relu_stack.0.bias : Float(512, strides=[1], requires_grad=1, device=cpu),\n",
      "      %linear_relu_stack.2.weight : Float(512, 512, strides=[512, 1], requires_grad=1, device=cpu),\n",
      "      %linear_relu_stack.2.bias : Float(512, strides=[1], requires_grad=1, device=cpu),\n",
      "      %linear_relu_stack.4.weight : Float(512, 512, strides=[512, 1], requires_grad=1, device=cpu),\n",
      "      %linear_relu_stack.4.bias : Float(512, strides=[1], requires_grad=1, device=cpu),\n",
      "      %linear_relu_stack.6.weight : Float(972, 512, strides=[512, 1], requires_grad=1, device=cpu),\n",
      "      %linear_relu_stack.6.bias : Float(972, strides=[1], requires_grad=1, device=cpu)):\n",
      "  %9 : Float(1, 9, strides=[9, 1], requires_grad=0, device=cpu) = onnx::Flatten[axis=1](%0) # /home/sehwan/.local/lib/python3.6/site-packages/torch/nn/modules/flatten.py:40:0\n",
      "  %10 : Float(1, 512, strides=[512, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%9, %linear_relu_stack.0.weight, %linear_relu_stack.0.bias) # /home/sehwan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1847:0\n",
      "  %11 : Float(1, 512, strides=[512, 1], requires_grad=1, device=cpu) = onnx::Relu(%10) # /home/sehwan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1298:0\n",
      "  %12 : Float(1, 512, strides=[512, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%11, %linear_relu_stack.2.weight, %linear_relu_stack.2.bias) # /home/sehwan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1847:0\n",
      "  %13 : Float(1, 512, strides=[512, 1], requires_grad=1, device=cpu) = onnx::Relu(%12) # /home/sehwan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1298:0\n",
      "  %14 : Float(1, 512, strides=[512, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%13, %linear_relu_stack.4.weight, %linear_relu_stack.4.bias) # /home/sehwan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1847:0\n",
      "  %15 : Float(1, 512, strides=[512, 1], requires_grad=1, device=cpu) = onnx::Relu(%14) # /home/sehwan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1298:0\n",
      "  %16 : Float(1, 972, strides=[972, 1], requires_grad=1, device=cpu) = onnx::Gemm[alpha=1., beta=1., transB=1](%15, %linear_relu_stack.6.weight, %linear_relu_stack.6.bias) # /home/sehwan/.local/lib/python3.6/site-packages/torch/nn/functional.py:1847:0\n",
      "  return (%16)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#export the model\n",
    "if EXPORT:\n",
    "    trained_model = NeuralNetwork()\n",
    "    input_x = torch.rand(1, 9);\n",
    "    trained_model.load_state_dict(torch.load('sehwan_landing_2x512'))\n",
    "    torch.onnx.export(trained_model, input_x, \"nn_TO_landing.onnx\", verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNetwork(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (linear_relu_stack): Sequential(\n",
      "    (0): Linear(in_features=9, out_features=512, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (3): ReLU()\n",
      "    (4): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (5): ReLU()\n",
      "    (6): Linear(in_features=512, out_features=972, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 9.2164e-03, -1.4809e-02, -5.0562e-01,  1.2283e+00,  1.0556e+00,\n",
       "          1.1183e+00,  8.7641e-01,  1.1405e+00,  1.2234e+00,  9.6782e-01,\n",
       "          1.2975e+00,  7.4504e-01,  9.6714e-01,  1.2972e+00,  3.6321e-01,\n",
       "          1.2828e+00,  1.0949e+00,  1.1513e+00,  8.9850e-01,  1.1175e+00,\n",
       "          1.2215e+00,  9.6679e-01,  1.2969e+00,  7.4293e-01,  9.6701e-01,\n",
       "          1.2970e+00,  7.7826e-01,  1.3023e+00,  1.1083e+00,  1.1625e+00,\n",
       "         -3.7129e-01, -4.8355e-01,  1.3361e-01,  1.0123e+00,  1.1525e+00,\n",
       "          6.0039e-01,  9.8441e-01,  1.2886e+00,  9.0220e-01,  1.4769e+00,\n",
       "          1.1473e+00,  1.1446e+00, -1.1276e+00, -4.1009e-01,  9.2832e-01,\n",
       "          1.0711e+00,  1.3912e+00, -2.7533e-01,  1.0050e+00,  1.3181e+00,\n",
       "          8.5082e-01,  1.3534e+00,  1.3154e+00,  1.1467e+00, -1.1199e+00,\n",
       "         -9.3229e-01,  9.2785e-01,  1.0808e+00,  1.4089e+00, -4.8493e-01,\n",
       "          1.0221e+00,  1.3398e+00,  8.0452e-01,  1.1459e+00,  1.3481e+00,\n",
       "          1.1486e+00, -1.3650e+00, -1.2170e+00,  8.7299e-01,  9.3067e-01,\n",
       "          1.4080e+00, -4.9567e-01,  1.0252e+00,  1.3579e+00,  7.8461e-01,\n",
       "          7.2855e-01,  1.2550e+00,  1.1397e+00, -1.6799e+00, -1.3101e+00,\n",
       "          6.8531e-01,  6.9191e-01,  1.4030e+00, -7.0255e-01,  1.0160e+00,\n",
       "          1.3707e+00,  7.3788e-01,  2.3284e-01,  1.0580e+00,  1.1327e+00,\n",
       "         -1.1464e+00, -1.2900e+00,  8.3065e-01,  3.0087e-01,  1.3329e+00,\n",
       "         -6.5366e-01,  9.9453e-01,  1.3796e+00,  6.9664e-01, -5.5987e-02,\n",
       "          7.7731e-01,  1.1308e+00, -9.5234e-01, -1.2230e+00,  9.4550e-01,\n",
       "          2.6350e-02,  1.2743e+00, -6.1215e-01,  9.7067e-01,  1.3867e+00,\n",
       "          6.6235e-01, -2.5630e-01,  4.4621e-01,  1.1312e+00, -8.0138e-01,\n",
       "         -1.2069e+00,  1.0447e+00, -1.6842e-01,  1.2134e+00, -5.7192e-01,\n",
       "          9.4520e-01,  1.3912e+00,  6.2530e-01, -3.9265e-01,  1.1907e-01,\n",
       "          1.1342e+00, -9.1747e-01, -1.0034e+00,  1.1038e+00, -3.3323e-01,\n",
       "          1.1328e+00, -5.1030e-01,  9.1891e-01,  1.3928e+00,  5.9349e-01,\n",
       "         -5.2783e-01, -1.1603e-01,  1.1392e+00, -6.9524e-01, -7.0235e-01,\n",
       "          1.1201e+00, -4.7490e-01,  1.0659e+00, -4.7695e-01,  8.9591e-01,\n",
       "          1.3936e+00,  5.6153e-01, -6.2005e-01, -2.5290e-01,  1.1452e+00,\n",
       "         -5.2926e-01, -2.9776e-01,  1.0949e+00, -5.9669e-01,  1.0073e+00,\n",
       "         -4.3721e-01,  8.7490e-01,  1.3954e+00,  5.2789e-01, -6.8484e-01,\n",
       "         -3.0392e-01,  1.1519e+00, -4.9669e-01,  1.0340e-01,  1.0328e+00,\n",
       "         -6.9471e-01,  9.4344e-01, -4.0031e-01,  8.5443e-01,  1.3969e+00,\n",
       "          4.9947e-01, -7.4688e-01, -2.9457e-01,  1.1577e+00, -3.8498e-01,\n",
       "          4.8354e-01,  9.5550e-01, -7.7156e-01,  8.9864e-01, -3.4233e-01,\n",
       "          8.3535e-01,  1.3966e+00,  4.7004e-01, -8.0117e-01, -2.4040e-01,\n",
       "          1.1644e+00, -4.2960e-01,  8.0451e-01,  8.7425e-01, -8.2729e-01,\n",
       "          8.7784e-01, -2.3275e-01,  8.1761e-01,  1.3968e+00,  4.5594e-01,\n",
       "         -8.5998e-01, -1.4153e-01,  1.1722e+00, -2.4959e-01,  8.9815e-01,\n",
       "          8.0476e-01, -8.6577e-01,  8.7727e-01, -1.2160e-01,  7.7793e-01,\n",
       "          1.3989e+00,  4.3171e-01, -9.4579e-01,  1.4906e-01,  1.1880e+00,\n",
       "          2.0436e-01,  1.0707e+00,  8.3408e-01, -8.6181e-01,  9.7600e-01,\n",
       "         -1.7024e-01,  7.4445e-01,  1.4017e+00,  3.8764e-01, -9.2756e-01,\n",
       "          4.4900e-01,  1.2033e+00,  6.3187e-02,  6.9299e-01,  9.9854e-01,\n",
       "         -7.1555e-01,  1.0570e+00, -6.4055e-02,  6.9028e-01,  1.4095e+00,\n",
       "          3.0857e-01, -9.0755e-01,  7.2678e-01,  1.2364e+00,  3.7782e-01,\n",
       "         -1.6844e+00,  1.1664e+00, -3.0406e-01,  1.0537e+00, -1.1628e-01,\n",
       "          4.7360e-01,  1.5522e+00, -2.9302e-01,  4.5406e-01,  2.3993e-01,\n",
       "          1.3178e+00, -4.8451e-01,  2.3304e-01,  6.6869e-02,  1.0271e-01,\n",
       "          5.5309e-01,  4.1450e-01, -4.6284e-01,  2.0864e+00, -1.0817e+00,\n",
       "         -1.8326e+00,  1.5457e+00, -1.4942e-01,  1.0098e-01, -3.9792e-01,\n",
       "         -3.8460e-01, -1.1883e+00, -8.7874e-01,  4.3723e-01, -1.8281e-01,\n",
       "         -4.1677e-01,  9.5777e-02, -2.0309e-01, -2.9916e-01,  1.0362e-01,\n",
       "         -1.9098e-01, -1.7338e-01,  7.8680e-02, -1.9056e-01, -9.2980e-02,\n",
       "         -1.4825e-01,  1.2383e+00,  2.4187e+00, -8.2858e-01, -3.5529e-01,\n",
       "          1.3126e+00,  5.8106e-02,  1.2913e+00,  1.4220e-01,  2.8117e-01,\n",
       "         -2.2827e-01, -6.1515e-01,  1.1445e+00, -7.8183e-01, -2.8237e-01,\n",
       "          6.1809e-01,  3.8983e-01, -7.8546e-02, -3.9388e-01, -6.4065e-01,\n",
       "         -1.1059e+00, -1.1205e+00, -9.0250e-02, -3.4509e-02, -3.9209e-01,\n",
       "          1.0277e+00,  2.3452e+00, -5.7355e-02, -1.1744e-01,  1.4459e+00,\n",
       "          1.3619e-03,  1.2541e+00,  2.2714e-01,  2.2221e-01,  2.0931e-01,\n",
       "         -5.1934e-01,  1.2728e+00, -3.3344e-01, -8.6838e-01, -6.1473e-01,\n",
       "         -3.4202e-01,  1.9054e-01, -1.0087e+00, -7.7350e-02, -6.6289e-01,\n",
       "         -2.1160e-01, -6.1585e-01,  6.9829e-01, -1.1842e+00,  9.7667e-01,\n",
       "          2.2387e+00, -3.5884e-01, -6.3661e-02,  1.6577e+00, -1.6914e-01,\n",
       "          1.3156e+00,  2.2646e-01,  9.1426e-02,  2.5788e-01, -3.6646e-01,\n",
       "          7.4490e-01, -1.0437e+00, -4.2960e-01,  6.3654e-01, -8.0079e-01,\n",
       "         -1.5881e+00,  7.3021e-01, -8.1374e-01, -1.1553e+00, -8.8554e-01,\n",
       "          5.0075e-01,  6.7084e-01, -1.1654e+00,  9.9926e-01,  2.1947e+00,\n",
       "         -3.0015e-02, -4.2781e-02,  1.6327e+00, -2.2227e-01,  1.3261e+00,\n",
       "          2.4511e-01, -4.8751e-01,  4.0474e-01, -2.4602e-01,  1.0632e+00,\n",
       "         -1.8945e+00, -1.6379e+00,  7.8055e-01, -1.0170e+00, -1.6795e+00,\n",
       "          8.9497e-01, -9.2853e-01, -5.1102e-01, -2.5517e-01, -3.8999e-01,\n",
       "          2.5446e-01, -9.1305e-01,  9.8521e-01,  2.2242e+00, -1.2617e-01,\n",
       "         -6.9047e-02,  1.6147e+00,  9.2395e-02,  1.2839e+00,  2.9541e-01,\n",
       "         -2.9922e-01,  3.6142e-01, -1.5186e-01, -1.2193e-01, -1.5605e+00,\n",
       "         -1.6951e+00,  6.1736e-03, -1.2269e+00, -1.4806e+00,  1.2111e-01,\n",
       "         -1.4037e+00, -8.2890e-01, -4.5438e-01, -9.9410e-01, -1.5647e-02,\n",
       "         -8.0841e-01,  9.6441e-01,  2.2236e+00, -4.7103e-01, -5.8658e-02,\n",
       "          1.5580e+00,  2.2046e-01,  1.2338e+00,  2.6015e-01, -3.7575e-01,\n",
       "          3.1504e-01, -1.1776e-01,  2.0499e-01, -1.4215e+00, -2.2139e+00,\n",
       "          1.9947e-01, -1.9962e+00, -2.1388e+00,  1.1876e+00, -1.5861e+00,\n",
       "         -3.0647e-01,  6.6560e-02, -1.7083e+00, -3.9018e-01,  5.1374e-03,\n",
       "          9.6479e-01,  2.2257e+00, -6.0600e-01, -6.0727e-02,  1.5588e+00,\n",
       "         -5.1750e-01,  1.2248e+00,  2.5388e-01, -1.1978e-01,  3.1795e-01,\n",
       "         -1.1127e-01, -1.2862e-01, -1.0332e+00, -1.7053e+00,  3.4166e-01,\n",
       "         -1.0042e+00, -1.9093e+00,  9.6463e-01, -1.2941e+00, -6.6860e-01,\n",
       "          7.0986e-02, -1.4162e+00, -9.7397e-01,  2.8031e-01,  9.6413e-01,\n",
       "          2.2248e+00, -6.3420e-01, -5.8763e-02,  1.5588e+00, -6.0103e-01,\n",
       "          1.2164e+00,  2.9524e-01, -1.8183e-01,  3.1787e-01, -1.1095e-01,\n",
       "         -1.8539e-01, -8.8153e-01, -1.6476e+00,  6.4941e-01, -5.4570e-01,\n",
       "         -1.9716e+00,  1.1047e+00, -1.0129e+00, -6.5870e-01, -5.5221e-03,\n",
       "         -9.9560e-01, -1.0488e+00,  2.8818e-01,  9.6293e-01,  2.2236e+00,\n",
       "         -5.8229e-01, -5.9111e-02,  1.5595e+00, -5.8061e-01,  1.2167e+00,\n",
       "          2.9529e-01, -1.7236e-01,  3.1741e-01, -1.1185e-01, -1.9731e-01,\n",
       "         -8.5213e-01, -1.6714e+00,  8.3969e-01, -2.6529e-01, -1.7705e+00,\n",
       "          9.6016e-01, -9.4212e-01, -9.2589e-01,  1.5181e-01, -7.4028e-01,\n",
       "         -1.0459e+00,  5.2200e-01,  9.6528e-01,  2.2235e+00, -4.5923e-01,\n",
       "         -5.9450e-02,  1.5588e+00, -5.0126e-01,  1.2177e+00,  2.9629e-01,\n",
       "         -7.8334e-02,  3.1779e-01, -1.1019e-01, -1.9084e-01, -8.3170e-01,\n",
       "         -1.6714e+00,  7.8349e-01, -1.4920e-01, -1.6851e+00,  8.9299e-01,\n",
       "         -7.3787e-01, -7.8315e-01, -2.5959e-01, -4.5982e-01, -8.5174e-01,\n",
       "          4.9143e-01,  9.6478e-01,  2.2250e+00, -3.8273e-01, -5.2890e-02,\n",
       "          1.5608e+00, -4.6259e-01,  1.2163e+00,  2.9523e-01, -3.1619e-02,\n",
       "          3.1748e-01, -1.1021e-01, -1.5661e-01, -7.8366e-01, -1.6402e+00,\n",
       "          7.8841e-01, -4.7406e-03, -1.6765e+00,  1.0288e+00, -5.6503e-01,\n",
       "         -6.8891e-01, -2.2459e-01, -1.6350e-01, -6.9787e-01,  3.6098e-01,\n",
       "          9.6317e-01,  2.2234e+00, -3.1804e-01, -5.3603e-02,  1.5603e+00,\n",
       "         -4.2652e-01,  1.2173e+00,  2.9558e-01,  4.9800e-02,  3.1731e-01,\n",
       "         -1.1093e-01, -1.1921e-01, -6.7041e-01, -1.6322e+00,  8.7442e-01,\n",
       "          2.2649e-01, -1.6563e+00,  1.1277e+00, -3.9644e-01, -6.7786e-01,\n",
       "         -3.6033e-01,  8.7600e-02, -6.0287e-01,  1.6886e-01,  9.6227e-01,\n",
       "          2.2254e+00, -2.6716e-01, -5.2192e-02,  1.5609e+00, -4.1886e-01,\n",
       "          1.2182e+00,  2.9466e-01,  1.0437e-01,  3.1786e-01, -1.1163e-01,\n",
       "         -8.4798e-02, -4.6772e-01, -1.5340e+00,  8.9316e-01,  5.1368e-01,\n",
       "         -1.5466e+00,  1.2353e+00, -2.3930e-01, -5.1813e-01, -3.6676e-01,\n",
       "          2.9745e-01, -3.6208e-01,  2.1734e-01,  9.6277e-01,  2.2254e+00,\n",
       "         -2.5005e-01, -5.2266e-02,  1.5609e+00, -3.9892e-01,  1.2170e+00,\n",
       "          2.9459e-01,  7.1139e-02,  3.1819e-01, -1.1132e-01, -7.0738e-02,\n",
       "         -2.7842e-01, -1.4035e+00,  1.0095e+00,  7.7947e-01, -1.3826e+00,\n",
       "          1.2512e+00, -6.6344e-02, -4.4048e-01, -6.5330e-02,  5.1603e-01,\n",
       "         -8.3810e-02,  2.3591e-01,  9.6393e-01,  2.2241e+00, -1.7407e-01,\n",
       "         -5.4044e-02,  1.5604e+00, -2.6653e-01,  1.2169e+00,  2.9716e-01,\n",
       "          1.8252e-01,  3.1725e-01, -1.1126e-01, -6.4628e-02, -1.6404e-01,\n",
       "         -1.2646e+00,  8.6048e-01,  8.6475e-01, -1.2639e+00,  1.2586e+00,\n",
       "          6.5997e-02, -1.4137e-01, -4.2928e-01,  7.0831e-01,  1.5104e-01,\n",
       "          1.4575e-01,  9.6301e-01,  2.2239e+00, -2.9986e-01, -4.9682e-02,\n",
       "          1.5657e+00, -5.4789e-01,  1.2163e+00,  2.9605e-01,  1.5757e-01,\n",
       "          3.1757e-01, -1.1058e-01, -1.3827e-01,  1.7223e-01, -1.8014e-01,\n",
       "          1.6329e-01,  5.9226e-01, -7.0222e-01,  5.7402e-01,  6.4373e-01,\n",
       "          5.2685e-01, -6.6243e-01,  1.1223e+00, -4.8233e-02, -2.3556e-01,\n",
       "          9.6453e-01,  2.2247e+00, -4.6398e-01, -5.0036e-02,  1.5658e+00,\n",
       "         -6.1635e-01,  1.2157e+00,  2.9510e-01,  1.4444e-01,  3.1843e-01,\n",
       "         -1.1067e-01, -1.2137e-01,  5.4238e-01,  6.8586e-01,  3.9968e-01,\n",
       "          7.3919e-01, -1.8458e-01,  6.5007e-01,  1.1496e+00,  6.3962e-01,\n",
       "         -3.5651e-01,  1.3246e+00, -1.4493e-01, -1.9897e-01,  9.6437e-01,\n",
       "          2.2241e+00, -5.0461e-01, -4.7828e-02,  1.5654e+00, -6.1237e-01,\n",
       "          1.2184e+00,  2.9528e-01,  2.6628e-01,  3.1799e-01, -1.1156e-01,\n",
       "         -1.2674e-01,  3.4038e-01,  7.0082e-01, -2.0095e-02,  6.9920e-01,\n",
       "          4.5058e-01, -6.7010e-03,  8.1743e-01,  2.5898e-01, -2.2742e-01,\n",
       "          3.7554e-01,  1.9279e-01, -2.2295e-01,  9.6382e-01,  2.2240e+00,\n",
       "         -8.3973e-02, -5.0498e-02,  1.5666e+00, -3.2718e-01,  1.2161e+00,\n",
       "          2.9510e-01, -7.4296e-03,  3.1755e-01, -1.1108e-01, -1.8302e-01,\n",
       "         -6.1963e-01, -1.4803e-01,  9.9172e-02,  6.1521e-01, -6.5294e-01,\n",
       "          4.9707e-01, -7.3582e-01, -3.4509e-01, -4.2943e-01,  1.1212e-01,\n",
       "          9.9596e-01,  1.1315e-01, -2.3741e-01,  6.4669e-02,  1.5990e-02,\n",
       "          3.8428e-01,  5.6370e-02, -1.2135e-02, -3.0321e-01, -2.3297e-01,\n",
       "          1.4246e-01,  2.7148e-02,  1.1306e-01,  1.0882e-01, -1.2418e+00,\n",
       "          1.1092e+00, -2.3214e-01, -2.0952e+00,  4.6813e-01,  8.7849e-01,\n",
       "         -9.8775e-01,  3.6721e-01,  7.4458e-01, -1.5093e+00, -3.3977e-02,\n",
       "          1.4669e+00, -1.2060e+00,  6.2809e-01,  8.7720e-01, -2.0580e+00,\n",
       "          1.2350e+00, -1.5356e-01, -7.5071e-01,  6.7222e-01, -4.2564e-01,\n",
       "         -1.7118e+00,  8.6414e-01,  2.1125e-01, -8.7422e-01,  1.1680e+00,\n",
       "         -1.7463e-01, -1.4856e+00,  1.6423e+00, -1.0177e+00, -4.8861e-01,\n",
       "          8.4863e-01, -9.2956e-01, -1.5746e+00,  1.5696e+00, -1.3679e+00,\n",
       "         -6.7632e-01,  6.2766e-01,  3.7840e-01, -1.2966e+00,  1.2575e+00,\n",
       "         -6.6680e-01, -1.5159e-01,  9.0451e-01, -1.1628e+00, -1.4263e+00,\n",
       "          1.4159e+00, -9.9951e-01, -2.6501e-01,  2.8463e-01,  2.6460e-01,\n",
       "         -1.1626e+00,  6.4224e-01, -3.4938e-01,  7.9846e-02,  2.9064e-01,\n",
       "         -6.8111e-01, -1.2157e+00,  1.6121e+00, -1.6518e+00,  1.1010e-01,\n",
       "         -8.2119e-03,  1.7394e-01, -1.0840e+00,  1.8884e-01, -2.6716e-01,\n",
       "          1.3691e-01, -1.0435e-01, -6.2664e-01, -9.9951e-01,  1.0215e+00,\n",
       "         -1.0909e+00,  3.6378e-01, -2.6011e-01,  4.3410e-02, -9.2331e-01,\n",
       "         -1.2310e-01, -4.2667e-01,  1.9706e-01, -5.3346e-01, -4.3116e-01,\n",
       "         -8.4762e-01,  6.5765e-01, -9.2784e-01,  4.5925e-01, -4.0272e-01,\n",
       "         -5.1748e-02, -8.9649e-01, -2.9677e-01, -4.3367e-01,  3.4505e-01,\n",
       "         -8.7917e-01, -2.5838e-01, -7.9339e-01,  3.7210e-01, -7.3169e-01,\n",
       "          4.9759e-01, -4.9687e-01, -1.2375e-01, -9.0111e-01, -3.8251e-01,\n",
       "         -3.8222e-01,  3.1232e-01, -1.0881e+00, -2.1211e-01, -7.3139e-01,\n",
       "          1.7799e-01, -5.6082e-01,  5.0902e-01, -5.5728e-01, -1.8126e-01,\n",
       "         -9.2342e-01, -4.2056e-01, -3.0290e-01,  2.4593e-01, -1.2259e+00,\n",
       "         -1.8936e-01, -6.4036e-01,  6.2228e-02, -4.1988e-01,  5.0598e-01,\n",
       "         -5.9078e-01, -2.2632e-01, -9.5498e-01, -4.1250e-01, -1.6442e-01,\n",
       "          2.0995e-01, -1.3068e+00, -1.8044e-01, -5.3962e-01,  1.5920e-02,\n",
       "         -3.1974e-01,  4.8017e-01, -6.1067e-01, -2.4697e-01, -9.9439e-01,\n",
       "         -3.9413e-01, -2.6411e-02,  1.9396e-01, -1.3595e+00, -1.5863e-01,\n",
       "         -4.4978e-01,  8.3670e-03, -2.4065e-01,  4.4773e-01, -6.1780e-01,\n",
       "         -2.4490e-01, -1.0483e+00, -3.6539e-01,  1.1615e-01,  2.0411e-01,\n",
       "         -1.3979e+00, -1.3186e-01, -3.8231e-01,  3.1201e-02, -1.8626e-01,\n",
       "          4.1228e-01, -6.1821e-01, -2.3382e-01, -1.1018e+00, -3.3104e-01,\n",
       "          2.4372e-01,  2.4741e-01, -1.4190e+00, -9.9437e-02, -3.2464e-01,\n",
       "          7.5055e-02, -1.5226e-01,  3.7401e-01, -6.0821e-01, -2.1392e-01,\n",
       "         -1.1528e+00, -2.8909e-01,  3.5587e-01,  3.0568e-01, -1.4142e+00,\n",
       "         -8.1074e-02, -2.7758e-01,  1.3887e-01, -1.4016e-01,  3.4000e-01,\n",
       "         -5.8915e-01, -1.9985e-01, -1.1912e+00, -2.3858e-01,  4.4676e-01,\n",
       "          3.7094e-01, -1.3801e+00, -8.9302e-02, -2.3563e-01,  2.2156e-01,\n",
       "         -1.5560e-01,  2.7365e-01, -5.1760e-01, -1.4534e-01, -1.2633e+00,\n",
       "         -1.3585e-01,  5.8226e-01,  5.3000e-01, -1.2025e+00, -1.8553e-01,\n",
       "         -1.3030e-01,  4.4366e-01, -2.2030e-01,  1.6654e-01, -4.5186e-01,\n",
       "         -9.6689e-03, -1.3177e+00, -5.1828e-02,  7.2374e-01,  5.9849e-01,\n",
       "         -9.5835e-01, -3.0566e-01, -7.0381e-02,  6.7936e-01, -2.8570e-01,\n",
       "          6.5139e-02, -3.3076e-01,  1.4169e-01, -1.2907e+00, -3.7988e-02,\n",
       "          8.6070e-01,  7.3565e-01, -4.5382e-01, -4.8030e-01,  1.2537e-01,\n",
       "          9.3065e-01, -2.9586e-01]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example = torch.rand(1,9)\n",
    "\n",
    "# Use torch.jit.trace to generate a torch.jit.ScriptModule via tracing.\n",
    "\n",
    "\n",
    "if EXPORT_CPP:\n",
    "    trained_model = NeuralNetwork()\n",
    "    trained_model.load_state_dict(torch.load('sehwan_landing_2x512'))\n",
    "    print(trained_model)\n",
    "    sm = torch.jit.trace(trained_model, example)\n",
    "    #sm = torch.jit.script(model)\n",
    "    sm.save(\"nn_TO_landing.pt\")\n",
    "\n",
    "sm(torch.ones(1, 9))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
